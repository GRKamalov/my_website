---
categories:  
- ""    #the front matter should be like the one found in, e.g., blog2.md. It cannot be like the normal Rmd we used
- ""
date: "2021-10-20"
description: My Data Analytics projects at London Business School # the title that will show up once someone gets to this page
draft: false
#image: spices.jpg # save picture in \static\img\blogs. Acceptable formats= jpg, jpeg, or png . Your iPhone pics wont work

keywords: ""
slug: lbs # slug is the shorthand URL address... no spaces plz
title: Data Analytics
--- 

Here I will be posting some of the most thrilling graphical insights I was able to obtain and code during the Data Analytics course at London Business School


German Elections: the Power of Polls
=====================================

The victory of SPD and the spectacular loss of the late coalition became a surprise for everyone except those who took Data Analytics at LBS! Here, we can observe the evolution of German election poll results, and clearly see the rise of SPD, and the decline of their competitors:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
library(tidyverse)  
library(mosaic)
library(ggthemes)
library(lubridate)
library(fivethirtyeight)
library(here)
library(ggplot2)
library(dplyr)
library(skimr)
library(janitor)
library(vroom)
library(tidyquant)
library(rvest)
library(ggrepel)
library(lubridate)
library(fivethirtyeight)
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)

library(data.table)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(rvest)
library(infer)

```


```{r, scrape_wikipedia_polling_data, warnings= FALSE, message=FALSE, echo = FALSE}
url <- "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2021_German_federal_election"

# similar graphs and analyses can be found at 
# https://www.theguardian.com/world/2021/jun/21/german-election-poll-tracker-who-will-be-the-next-chancellor
# https://www.economist.com/graphic-detail/who-will-succeed-angela-merkel


# get tables that exist on wikipedia page 
tables <- url %>% 
  read_html() %>% 
  html_nodes(css="table")


# parse HTML tables into a dataframe called polls 
# Use purr::map() to create a list of all tables in URL
polls <- map(tables, . %>% 
             html_table(fill=TRUE)%>% 
             janitor::clean_names())


# list of opinion polls
german_election_polls <- polls[[1]] %>% # the first table on the page contains the list of all opinions polls
  slice(2:(n()-1)) %>%  # drop the first row, as it contains again the variable names and last row that contains 2017 results
  mutate(
         # polls are shown to run from-to, e.g. 9-13 Aug 2021. We keep the last date, 13 Aug here, as the poll date
         # and we extract it by picking the last 11 characters from that field
         end_date = str_sub(fieldwork_date, -11),
         
         # end_date is still a string, so we convert it into a date object using lubridate::dmy()
         end_date = dmy(end_date),
         
         # we also get the month and week number from the date, if we want to do analysis by month- week, etc.
         month = month(end_date),
         week = isoweek(end_date)
         )
```


```{r, warning = FALSE,  message = FALSE, echo = FALSE}
library(data.table)
library(latex2exp)
library(reshape2)
colors = c("black", "brown4", "deepskyblue4", "goldenrod3", "blue4", "green4")


#Clen NAs if there are any, delete irrelevant columns and create one technical vector:
polls <- as.data.table(german_election_polls)
polls <- polls[complete.cases(polls), ]
polls[,1:4 := NULL] 
polls[,11:12 := NULL]
polls[,c("fw", "others", "lead") := NULL]

labels_vector <- c(paste("Union", polls[end_date == max(end_date), union]), paste("SPD", polls[end_date == max(end_date), spd]), paste("AfD", polls[end_date == max(end_date), af_d]), paste("FDP", polls[end_date == max(end_date), fdp]), paste("Linke", polls[end_date == max(end_date), linke]), paste("GrÃ¼ne", polls[end_date == max(end_date), grune]))

#Reshape the data for multi-column plotting:
polls <- melt(polls, id="end_date", value.name = "data")

#Do the plotting. We start with printing out the distinct poll results, then adding the simple MA to the graphs:
ggplot(polls, aes(x = end_date, y = data, colour = variable)) + 
geom_point(alpha = 0.4, cex = 1.15) + 
geom_ma(aes(x = end_date+10), ma_fun = SMA, n = 14, position = "identity", linetype = "solid", size = 0.65)+
#Ensure the color scheme is aligned with the original plot:
scale_color_manual(values = c(colors), labels = labels_vector) + 
#Add the horizontal line grid:
geom_hline(yintercept = seq(5,45,10), linetype = "dotted", size = 0.5, color = alpha("grey", 0.5))+
#Delete the default grid:
theme_bw()+
#Add the custom grid, amend the style and contents of legend
theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "white"),  legend.title = element_text(size = 7.5), legend.position = c(0.835,0.8), legend.background = element_rect(fill = "white" ,colour = "black ", size = 0.3))+
geom_vline(xintercept = max(polls$end_date), linetype = "dotted", size = 0.5)+
guides(col=guide_legend("24 Sep 2021\n 14-day rolling average %"))+
#Finally, make the axis labels match the original plot
scale_x_continuous(name = "Polls end date", breaks = as.Date(c("2021-01-01", "2021-03-01", "2021-05-01", "2021-07-01", "2021-09-01"), "%Y-%m-%d"), labels = c("Jan 2021", "Mar", "May", "Jul", "Sep")) +
scale_y_continuous(name = "Percentage of votes cast", breaks = seq(5,45,10), labels = c(5,15,25,35,"45%"), limits = c(4,46))
#here we are!

```


London Bike Rentals
========================

As a frequent user of Santander Bikes, I was very curious to see the evolution of London bike rentals, as well as the dynamic across seasons, months, and weeks. Below you can see the evolution (both in absolute and relative terms) of London bike rentals during the period from 2016 to 2021:

```{r tfl_percent_change, echo=FALSE, out.width="100%", echo = FALSE, message = FALSE, warning = FALSE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))


```
```{r, fig.height = 8, fig.width = 10, warning = FALSE, echo = FALSE, message = FALSE}
#As discussed in Slack, there are some issues with weeeks 53/1 around January the 1st of each year. Let's try fix it:
library(scales)
library(data.table)
bike <- as.data.table(bike)
for (i in 1:nrow(bike)){
  if(bike[i,]$week == 53 & bike[i,]$month == "Jan"){
    bike[i,]$year <- bike[i,]$year -1 
  }
}
for (i in 1:nrow(bike)){
  if(bike[i,]$week == 52 & bike[i,]$month == "Jan"){
    bike[i,]$year <- bike[i,]$year -1 
  }
}
bike <- bike %>% filter(year %in% c(2016:2021)) #since we don't really need earlier periods

#Let's start with the first graph:


#We will be working with dataset bike1 for the first plot
bike1 <- bike %>% 
  group_by(year, month) %>% 
  summarize(mean_hired := mean(bikes_hired)) 
#Calculate monthly averages for 2016-2019 and assign them to bike1
trendline <- bike1 %>% 
  filter(year %in% c(2016:2019)) %>%
  group_by(month) %>%
  summarize(trend := mean(mean_hired))
trend <- trendline$trend
trend[1:nrow(bike1)] <- trend
bike1$trend <- trend

#Proceed to plotting:
ggplot(bike1, aes(x = month, y = mean_hired))+
  geom_line(aes(group=1))+
  geom_ribbon(aes(ymin= mean_hired, ymax= ifelse(trend > mean_hired, trend, mean_hired), group = 1), 
              fill = "red", alpha = 0.5) +
  geom_ribbon(aes(ymin= mean_hired, ymax= ifelse(trend < mean_hired, trend, mean_hired), group = 1), 
              fill = "darkseagreen3", alpha = 0.5) +
  geom_line(aes(x = month, y = trend, group = 1), col = "purple", size = 1) +
  facet_wrap(~year) +
  scale_x_discrete( name = " ") + 
  scale_y_continuous( name = "Bike rentals")+
  theme_bw()+
  ggtitle("Monthly changes in TfL bike rentals \n Change from monthly average shown in blue  \n and calculated betwee 2016-2019")+
  labs(caption = "Source: TfL, London Data Store")




```

```{r, fig.height = 8, figh.width = 10, echo = FALSE, message = FALSE, warning = FALSE}
#proceed to the second plot:
#Our algorithm would not differ significantly:

bike1 <- bike %>% 
  group_by(year, week) %>% 
  summarize(mean_hired := mean(bikes_hired)) 
#Calculate monthly averages for 2016-2019 and assign them to bike1
trendline <- bike1 %>% 
  filter(year %in% c(2016:2019)) %>%
  group_by(week) %>%
  summarize(trend := mean(mean_hired))
trend <- trendline$trend
trend[1:nrow(bike1)] <- trend
bike1$trend <- trend

#create a variable for percentage point change:
bike1 <- bike1 %>% mutate(weekly_deviation = (mean_hired-trend)/trend*100)

ggplot(bike1, aes(x = week, y = weekly_deviation))+
  geom_rect(mapping = aes(xmin = 14, xmax = 26, ymin = -100, ymax=100), fill = alpha("darkgrey", 0.01))+
  geom_rect(mapping = aes(xmin = 40, xmax = 52, ymin = -100, ymax=100),fill = alpha("darkgrey", 0.01))+
  geom_line(aes(group=1), size = 0.5)+
  geom_ribbon(aes(ymin= weekly_deviation, ymax= ifelse(weekly_deviation > 0 , weekly_deviation, 0), group = 1), 
              fill = "red", alpha = 0.5) +
  geom_ribbon(aes(ymin= weekly_deviation, ymax= ifelse(weekly_deviation < 0 , weekly_deviation, 0), group = 1), 
              fill = "darkseagreen3", alpha = 0.5) +
  
  facet_wrap(~year)+
  scale_x_continuous( name = "week") + 
  scale_y_continuous( name = "Bike rentals", breaks = c(-100, -50, 0, 50, 100), labels = label_percent()(c(-1,-0.5,0,0.5,1)), limits = c(-100,100))+
  theme_bw()+
  ggtitle("Weekly changes in TfL bike rentals \n %change from weekly averages  \n calculated betwee 2016-2019")+
  labs(caption = "Source: TfL, London Data Store") 

```
